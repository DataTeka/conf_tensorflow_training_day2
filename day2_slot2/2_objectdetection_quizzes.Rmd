---
title: "Object detection"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
knitr::opts_chunk$set(echo = FALSE)
```


## Multiple object classification 

The quiz starts from the `classification_localization.Rmd` notebook.


### Quiz 1

We've just seen how to classify a single object in an image. 
What if we wanted to classify multiple objects?

Choose all statements that are true.

```{r quiz1}
quiz(
  question("If we wanted to classify multiple objects in an image, ...",
    answer("... we would have to change the data generator to use multi-hot encoding"),
    answer("between 0.8 and 0.9", correct = TRUE),
    answer("between 0.9 and 0.95")
  )
)
```


### Quiz 2

Modify your model to also predict `age`. That is, remove `age` from the predictors and use it as a second target, together with `salary`.

Train for 20 epochs just as we did before.


```{r quiz2}
quiz(
  question("What can you say regarding accuracy on salary prediction on the one hand, and mean squared error on age on the other hand?",
    answer("accuracy on salary is about the same as before, MSE on age is around 50"),
    answer("accuracy on salary is noticeably worse, MSE on age is around 50"),
    answer("accuracy on salary is noticeably worse, MSE on age is around 100", correct = TRUE)
  )
)
```


## Embeddings for uncovering relationships 

All quizzes in this section start from the `embeddings_so.Rmd` notebook.

### Quiz 1

We just ran the embeddings model in `embeddings_so.Rmd`. 

Find the cosine similarity between the embedded representation of `R` and

- `Python`
- `Julia`

To answer this question, you will need to 

- extract the weight matrix for the "programming languages" embeddings layer,
- identify the rows for the two languages, respectively, and
- calculate cosine similarity

```{r quiz3}
quiz(
  question("In which region are the cosine similarities?",
    answer("between -0.2 and 0"),
    answer("between 0 and 0.2", correct = TRUE),
    answer("between 0.2 and 0.4")
  )
)
```


### Quiz 2

When showing the embeddings obtained for job values, we pointed out that the target variable chosen could have a significant effect.

Compare the `OperatingSystem` embeddings learned from predicting `JobSatisfaction` to those learned from predicting `EthicsChoice`. How different are they, looking at the 2d PCA reduction?

```{r quiz4}
quiz(
  question("The 2d reductions of OperatingSystem embeddings, when computed with targets EthicsChoice and JobSatisfaction, respectively, are",
    answer("very different"),
    answer("not too different", correct = TRUE)
  )
)
```


## Embeddings for improving accuracy

### Quiz 1

Try to further improve accuracy, starting from the embeddings model.

Things you could try:

- adding further specialized layers to the `prod_embed` branch and the `cont_dense` branches before concatenating them
- adding more capacity to the network in various ways
- changing activation functions
- preprocessing the data differently / feature engineering

Some concrete ideas:

- instead of scaling or normalizing the continuous data (`Quant` and `Val`), try binning them
- try including more than just the top 500 products
- try including salesperson ID

Feel free to try whatever you like best / comes to mind!

## Embeddings on the Census Income dataset (optional)

### Quiz 1

We're continuing from the `heterogeneous_data_1.Rmd` notebook.
Can you improve accuracy using embeddings? 

We've copied some common, reusable code from that notebook to `heterogeneous_data_2.Rmd`.
Please use that to continue the task (you can also use any snippets you have left over from the functional API exercise of course!)