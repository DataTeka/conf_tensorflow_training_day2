---
title: "Deep learning for structured data"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
knitr::opts_chunk$set(echo = FALSE)
```


## Embeddings for uncovering relationships 

All quizzes in this section start from the `embeddings_so.Rmd` notebook.

### Quiz 1

We just ran the embeddings model in `embeddings_so.Rmd`. 

Find the cosine similarity between the embedded representation of `R` and

- `Python`
- `Julia`

To answer this question, you will need to 

- extract the weight matrix for the "programming languages" embeddings layer,
- identify the rows for the two languages, respectively, and
- calculate cosine similarity

```{r quiz1}
quiz(
  question("In which region are the cosine similarities?",
    answer("between -0.2 and 0"),
    answer("between 0 and 0.2", correct = TRUE),
    answer("between 0.2 and 0.4")
  )
)
```


### Quiz 2

When showing the embeddings obtained for job values, we pointed out that the target variable chosen could have a significant effect.

Compare the `OperatingSystem` embeddings learned from predicting `JobSatisfaction` to those learned from predicting `EthicsChoice`. How different are they, looking at the 2d PCA reduction?

```{r quiz2}
quiz(
  question("The 2d reductions of OperatingSystem embeddings, when computed with targets EthicsChoice and JobSatisfaction, respectively, are",
    answer("very different"),
    answer("not too different", correct = TRUE)
  )
)
```


## Embeddings for improving accuracy

### Quiz 1

Try to further improve accuracy, starting from the embeddings model.

Things you could try:

- adding further specialized layers to the `prod_embed` branch and the `cont_dense` branches before concatenating them
- adding more capacity to the network in various ways
- changing activation functions
- preprocessing the data differently / feature engineering

Some concrete ideas:

- instead of scaling or normalizing the continuous data (`Quant` and `Val`), try binning them
- try including more than just the top 500 products
- try including salesperson ID

Feel free to try whatever you like best / comes to mind!